# ğŸ§  AIDEN Interface

> The AI cockpit for defense strategy, genomic augmentation, and mission-aligned recursion.

## ğŸ§¬ Features

- LangChain-powered AI memory w/ recursive thread hydration
- Role-based access to project logs, actions, and personas
- Live contract feed, project analytics, risk profiles
- Voice-activated command console (Whisper + TTS)
- Hotkey-driven UI, tactical command bar (`/launch`, `/elevate`, `/readback`)

## ğŸ› ï¸ Setup

1. `git clone https://github.com/agiledefensesystems/aiden-interface`
2. Configure `.env.local` with:
   - `NEXT_SUPABASE_URL`
   - `NEXT_SUPABASE_SERVICE_ROLE_KEY`
   - `OPENAI_API_KEY`
   - `ELEVENLABS_API_KEY` (optional, for high-quality TTS)
3. `npm install && npm run dev`

## ğŸ” Access Roles

| Role | Capabilities |
|------|--------------|
| Admin (Devin) | Full memory + deployment + audit logs |
| AIDEN | Execution, recursion, output |
| Clinician | View-only diagnostics & TTS readouts |
| Investor | Project overview, ROI charts |
| Mentor | Annotate memory threads |

## ğŸ¤ Voice Activation

- Say: `"AIDEN, read my Spectra log from April 5th."`
- Press `R` to record, `M` to mute, `L` for last log playback.

## ğŸ“‹ Memory Schema

The AIDEN Interface uses a sophisticated memory schema to store and retrieve contextual information:

\`\`\`typescript
export type MemoryThread = {
  id: string
  title: string
  contextStack: string[]
  emotionalTuning: 'neutral' | 'strategic' | 'introspective' | 'aggressive' | 'empathic'
  accessLevel: 'public' | 'private' | 'restricted'
  rolesAllowed: string[]
  lastInvoked: string
  memoryVectors: number[]
  content: string
  createdAt: string
  updatedAt: string
}
\`\`\`

## ğŸ”„ Mode Switching

AIDEN supports different emotional tuning modes that affect how it processes and responds to information:

- **Neutral**: Balanced, objective analysis
- **Strategic**: Focus on long-term planning and optimization
- **Introspective**: Deep analysis and self-reflection
- **Aggressive**: Direct, action-oriented approach
- **Empathic**: Focus on human factors and emotional context

## ğŸ“Š Project Structure

\`\`\`
/
â”œâ”€â”€ app/                # Next.js app router
â”‚   â”œâ”€â”€ api/            # API routes for TTS, voice recognition
â”‚   â”œâ”€â”€ page.tsx        # Main interface
â”‚   â””â”€â”€ layout.tsx      # Root layout
â”œâ”€â”€ components/         # UI components
â”‚   â”œâ”€â”€ CommandBar.tsx  # Command input interface
â”‚   â”œâ”€â”€ MemoryView.tsx  # Memory thread viewer
â”‚   â”œâ”€â”€ VoiceConsole.tsx # Voice interaction console
â”‚   â””â”€â”€ ui/             # UI primitives
â”œâ”€â”€ lib/                # Core functionality
â”‚   â”œâ”€â”€ aiden.ts        # AIDEN agent implementation
â”‚   â”œâ”€â”€ tts.ts          # Text-to-speech functionality
â”‚   â”œâ”€â”€ voice-recognition.ts # Voice recognition
â”‚   â””â”€â”€ memory/         # Memory management
â””â”€â”€ public/             # Static assets
\`\`\`

## ğŸ“ License

Proprietary - All rights reserved
\`\`\`

Let's create a package.json file:
